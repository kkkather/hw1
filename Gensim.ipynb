{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7639ff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_corpus= [\n",
    "    \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "]\n",
    "stoplist = set('for a of the and to in is'.split())\n",
    "corpus= [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in text_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58cf741e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10, 0.5898341626740045), (30, 0.8075244024440723)]\n",
      "---------------------------------\n",
      "[(0, 0.4301019571350565), (1, 0.4301019571350565), (2, 0.2944198962221451), (3, 0.2944198962221451), (4, 0.2944198962221451), (5, 0.4301019571350565), (6, 0.4301019571350565)]\n",
      "[(2, 0.3726494271826947), (7, 0.5443832091958983), (8, 0.3726494271826947), (9, 0.3726494271826947), (10, 0.27219160459794917), (11, 0.3726494271826947), (12, 0.27219160459794917)]\n",
      "[(4, 0.438482464916089), (10, 0.32027755044706185), (12, 0.32027755044706185), (13, 0.438482464916089), (14, 0.6405551008941237)]\n",
      "[(3, 0.3449874408519962), (10, 0.5039733231394895), (13, 0.3449874408519962), (15, 0.5039733231394895), (16, 0.5039733231394895)]\n",
      "[(8, 0.30055933182961736), (11, 0.30055933182961736), (12, 0.21953536176370683), (17, 0.43907072352741366), (18, 0.43907072352741366), (19, 0.43907072352741366), (20, 0.43907072352741366)]\n",
      "[(21, 0.48507125007266594), (22, 0.48507125007266594), (23, 0.48507125007266594), (24, 0.24253562503633297), (25, 0.48507125007266594)]\n",
      "[(24, 0.31622776601683794), (26, 0.31622776601683794), (27, 0.6324555320336759), (28, 0.6324555320336759)]\n",
      "[(24, 0.20466057569885868), (26, 0.20466057569885868), (29, 0.40932115139771735), (30, 0.2801947048062438), (31, 0.40932115139771735), (32, 0.40932115139771735), (33, 0.40932115139771735), (34, 0.40932115139771735)]\n",
      "[(9, 0.6282580468670046), (26, 0.45889394536615247), (30, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "#训练tf-idf模型\n",
    "from gensim import models\n",
    "tfidf = models.TfidfModel(bow_corpus)# train the model\n",
    "words = \"system minors\".lower().split()# transform the \"system minors\" string\n",
    "print(tfidf[dictionary.doc2bow(words)])\n",
    "print('---------------------------------')\n",
    "#for corpus in bow_corpus:\n",
    "    #print(tfidf[corpus])\n",
    "for corpus in bow_corpus:\n",
    "    corpus_tfidf=tfidf[corpus]\n",
    "    print(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b80f1e54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'machine', 'interface', 'lab', 'abc', 'computer', 'applications'], ['survey', 'user', 'opinion', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'management', 'system'], ['system', 'human', 'system', 'engineering', 'testing', 'eps'], ['relation', 'user', 'perceived', 'response', 'time', 'error', 'measurement'], ['generation', 'random', 'binary', 'unordered', 'trees'], ['intersection', 'graph', 'paths', 'trees'], ['graph', 'minors', 'iv', 'widths', 'trees', 'well', 'quasi', 'ordering'], ['graph', 'minors', 'survey']]\n",
      "----------------------\n",
      "Dictionary(35 unique tokens: ['abc', 'applications', 'computer', 'human', 'interface']...)\n",
      "----------------------\n",
      "{'abc': 0, 'applications': 1, 'computer': 2, 'human': 3, 'interface': 4, 'lab': 5, 'machine': 6, 'opinion': 7, 'response': 8, 'survey': 9, 'system': 10, 'time': 11, 'user': 12, 'eps': 13, 'management': 14, 'engineering': 15, 'testing': 16, 'error': 17, 'measurement': 18, 'perceived': 19, 'relation': 20, 'binary': 21, 'generation': 22, 'random': 23, 'trees': 24, 'unordered': 25, 'graph': 26, 'intersection': 27, 'paths': 28, 'iv': 29, 'minors': 30, 'ordering': 31, 'quasi': 32, 'well': 33, 'widths': 34}\n",
      "----------------------\n",
      "{3: 2, 6: 1, 4: 2, 5: 1, 0: 1, 2: 2, 1: 1, 9: 2, 12: 3, 7: 1, 10: 3, 8: 2, 11: 2, 13: 2, 14: 1, 15: 1, 16: 1, 20: 1, 19: 1, 17: 1, 18: 1, 22: 1, 23: 1, 21: 1, 25: 1, 24: 3, 27: 1, 26: 3, 28: 1, 30: 2, 29: 1, 34: 1, 33: 1, 32: 1, 31: 1}\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "print(corpus)\n",
    "dictionary = corpora.Dictionary(corpus) #生成词典\n",
    "print('----------------------')\n",
    "print(dictionary)\n",
    "print('----------------------')\n",
    "print(dictionary.token2id) #存放的是单词-id key-value对\n",
    "print('----------------------')\n",
    "print(dictionary.dfs) #存放的是单词的出现频率\n",
    "bow_corpus=[dictionary.doc2bow(text) for text in corpus] #转化为向量形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25ded1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abc': 0, 'applications': 1, 'computer': 2, 'human': 3, 'interface': 4, 'lab': 5, 'machine': 6, 'opinion': 7, 'response': 8, 'survey': 9, 'system': 10, 'time': 11, 'user': 12, 'eps': 13, 'management': 14, 'engineering': 15, 'testing': 16, 'error': 17, 'measurement': 18, 'perceived': 19, 'relation': 20, 'binary': 21, 'generation': 22, 'random': 23, 'trees': 24, 'unordered': 25, 'graph': 26, 'intersection': 27, 'paths': 28, 'iv': 29, 'minors': 30, 'ordering': 31, 'quasi': 32, 'well': 33, 'widths': 34, 'an': 35, 'are': 36, 'art': 37, 'image': 38, 'life': 39, 'literature': 40, 'social': 41, 'summarize': 42, 'that': 43, 'works': 44, 'architectural': 45, 'dance,': 46, 'drama,': 47, 'etc': 48, 'film,': 49, 'including': 50, 'literature,': 51, 'modeling,': 52, 'music,': 53, 'painting,': 54, 'sculpture,': 55, 'creative': 56, 'it': 57, 'methods': 58, 'refers': 59, 'ways': 60, 'beautiful': 61, 'unique': 62}\n",
      "{3: 2, 6: 1, 4: 2, 5: 1, 0: 1, 2: 2, 1: 1, 9: 2, 12: 3, 7: 1, 10: 3, 8: 2, 11: 2, 13: 2, 14: 1, 15: 1, 16: 1, 20: 1, 19: 1, 17: 1, 18: 1, 22: 1, 23: 1, 21: 1, 25: 1, 24: 3, 27: 1, 26: 3, 28: 1, 30: 2, 29: 1, 34: 1, 33: 1, 32: 1, 31: 1, 40: 1, 37: 1, 36: 1, 44: 1, 43: 1, 42: 1, 41: 1, 39: 1, 35: 1, 38: 1, 50: 1, 51: 1, 54: 1, 55: 1, 45: 1, 52: 1, 53: 1, 46: 1, 47: 1, 49: 1, 48: 1, 57: 2, 59: 1, 56: 1, 60: 1, 58: 1, 62: 1, 61: 1}\n"
     ]
    }
   ],
   "source": [
    "#加入art语料库\n",
    "text_corpus= [ \"Human machine interface for lab abc computer applications\",\n",
    "    \"A survey of user opinion of computer system response time\",\n",
    "    \"The EPS user interface management system\",\n",
    "    \"System and human system engineering testing of EPS\",\n",
    "    \"Relation of user perceived response time to error measurement\",\n",
    "    \"The generation of random binary unordered trees\",\n",
    "    \"The intersection graph of paths in trees\",\n",
    "    \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "    \"Graph minors A survey\",\n",
    "    \"Literature and art are works that summarize social life in an image\",\n",
    "              \"including literature, painting, sculpture, architectural modeling, music, dance, drama, film, etc\",\n",
    "              \"It refers to creative ways and methods\",\n",
    "              \"It is unique and beautiful\",]\n",
    "stoplist = set('for a of the and to in is'.split())\n",
    "corpus= [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in text_corpus]\n",
    "from gensim import corpora\n",
    "dictionary = corpora.Dictionary(corpus) #生成词典\n",
    "print(dictionary.token2id) #存放的是单词-id key-value对\n",
    "print(dictionary.dfs) #存放的是单词的出现频率\n",
    "bow_corpus2=[dictionary.doc2bow(text) for text in corpus] #转化为向量形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02267e5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus_lsi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#训练LSA模型\u001b[39;00m\n\u001b[1;32m      2\u001b[0m lsi \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mLsiModel(bow_corpus2,id2word\u001b[38;5;241m=\u001b[39mdictionary, num_topics\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;66;03m# train the model\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mcorpus_lsi\u001b[49m)\n\u001b[1;32m      5\u001b[0m lsi\u001b[38;5;241m.\u001b[39mprint_topics(\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus_lsi' is not defined"
     ]
    }
   ],
   "source": [
    "#训练LSA模型\n",
    "lsi = models.LsiModel(bow_corpus2,id2word=dictionary, num_topics=2)# train the model\n",
    "\n",
    "nodes = list(corpus_lsi)\n",
    "lsi.print_topics(2) # 打印各topic的含义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6937907",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2个主题的单词分布为:\n",
      "\n",
      "(0, '0.042*\"trees\" + 0.030*\"it\" + 0.030*\"system\" + 0.027*\"graph\" + 0.024*\"user\" + 0.023*\"eps\" + 0.021*\"unique\" + 0.021*\"beautiful\" + 0.021*\"binary\" + 0.021*\"random\"')\n",
      "(1, '0.039*\"system\" + 0.031*\"user\" + 0.030*\"computer\" + 0.030*\"survey\" + 0.028*\"graph\" + 0.026*\"minors\" + 0.025*\"interface\" + 0.022*\"human\" + 0.022*\"time\" + 0.021*\"response\"')\n"
     ]
    }
   ],
   "source": [
    "#训练LDA模型\n",
    "lda = models.LdaModel(bow_corpus2,id2word=dictionary, num_topics=2)# train the model\n",
    "topic_list = lda.print_topics(2)\n",
    "print(\"2个主题的单词分布为:\\n\")\n",
    "for topic in topic_list:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed68e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0), (1, 0.12172779), (2, 1.0026273), (3, 0.22538371), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n",
      "2 1.0026273\n",
      "3 0.22538371\n",
      "1 0.12172779\n",
      "0 0.0\n",
      "4 0.0\n",
      "5 0.0\n",
      "6 0.0\n",
      "7 0.0\n",
      "8 0.0\n"
     ]
    }
   ],
   "source": [
    "from gensim import similarities\n",
    "\n",
    "index = similarities.SparseMatrixSimilarity(tfidf[bow_corpus], num_features=12)\n",
    "query_document = 'system engineering'.split()\n",
    "query_bow = dictionary.doc2bow(query_document)\n",
    "sims = index[tfidf[query_bow]]\n",
    "print(list(enumerate(sims)))\n",
    "for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
    "    print(document_number, score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e04250",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8318b091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfca5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
